import streamlit as st
import requests
import json
import subprocess
import os

st.title("üñºÔ∏è PNPT Free Clip ‚Äì –í–∏–∑—É–∞–ª –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é (—á–µ—Ä–µ–∑ Hugging Face, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)")

prompt = st.text_area("üé¨ –û–ø–∏—à–∏ –∏–¥–µ—é –∫–ª–∏–ø–∞:")
HF_TOKEN = "–≤—Å—Ç–∞–≤—å_—Å—é–¥–∞_—Ç–æ–∫–µ–Ω"

def generate_image(prompt):
    api_url = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-2"
    headers = {
        "Authorization": f"Bearer {HF_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {"inputs": prompt}
    try:
        response = requests.post(
            api_url,
            headers=headers,
            data=json.dumps(payload).encode("utf-8")
        )
        if response.status_code == 200:
            with open("generated.png", "wb") as f:
                f.write(response.content)
            return "generated.png"
        else:
            st.error("–û—à–∏–±–∫–∞ Hugging Face API: " + response.text)
            return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return None

if st.button("–°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª") and prompt:
    with st.spinner("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
        img_path = generate_image(prompt)
        if img_path:
            st.image(img_path, caption="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ AI")

            subprocess.call(
                "ffmpeg -y -loop 1 -i generated.png -c:v libx264 -t 5 -pix_fmt yuv420p output.mp4",
                shell=True
            )

            st.success("‚úÖ –í–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ!")
            st.video("output.mp4")